{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if a stand-up comedy will receive above or below average IMDb rating\n",
    "\n",
    "1) Train weak learners: Random Forrest, Stochastic Gradient Descent.\n",
    "\n",
    "2) Perform a grid search to find optimal parameters for an XGBoost classifier.\n",
    "\n",
    "3) Put all three models into an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"D:\\PROJECTS\\transnlp\\data\\processed\\processed_content_with_clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 28 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   S No.                 500 non-null    int64  \n",
      " 1   Tag                   500 non-null    object \n",
      " 2   URL                   500 non-null    object \n",
      " 3   Raw Transcript        500 non-null    object \n",
      " 4   Transcript            500 non-null    object \n",
      " 5   CleanTag              500 non-null    object \n",
      " 6   Year                  465 non-null    float64\n",
      " 7   Names                 500 non-null    object \n",
      " 8   Title                 480 non-null    object \n",
      " 9   runtime               434 non-null    float64\n",
      " 10  rating                425 non-null    float64\n",
      " 11  language              500 non-null    object \n",
      " 12  preprocessed_content  500 non-null    object \n",
      " 13  rating_type           425 non-null    object \n",
      " 14  f_words               500 non-null    int64  \n",
      " 15  s_words               500 non-null    int64  \n",
      " 16  word_count            500 non-null    int64  \n",
      " 17  diversity             500 non-null    int64  \n",
      " 18  diversity_ratio       500 non-null    float64\n",
      " 19  Culture               500 non-null    float64\n",
      " 20  UK                    500 non-null    float64\n",
      " 21  Crimes                500 non-null    float64\n",
      " 22  Situational           500 non-null    float64\n",
      " 23  Immigrants            500 non-null    float64\n",
      " 24  Relationships         500 non-null    float64\n",
      " 25  Politics              500 non-null    float64\n",
      " 26  cluster_LDA           500 non-null    int64  \n",
      " 27  cluster_tfidf         500 non-null    int64  \n",
      "dtypes: float64(11), int64(7), object(10)\n",
      "memory usage: 109.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 425 entries, 0 to 499\n",
      "Data columns (total 29 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   S No.                 425 non-null    int64  \n",
      " 1   Tag                   425 non-null    object \n",
      " 2   URL                   425 non-null    object \n",
      " 3   Raw Transcript        425 non-null    object \n",
      " 4   Transcript            425 non-null    object \n",
      " 5   CleanTag              425 non-null    object \n",
      " 6   Year                  417 non-null    float64\n",
      " 7   Names                 425 non-null    object \n",
      " 8   Title                 419 non-null    object \n",
      " 9   runtime               420 non-null    float64\n",
      " 10  rating                425 non-null    float64\n",
      " 11  language              425 non-null    object \n",
      " 12  preprocessed_content  425 non-null    object \n",
      " 13  rating_type           425 non-null    object \n",
      " 14  f_words               425 non-null    int64  \n",
      " 15  s_words               425 non-null    int64  \n",
      " 16  word_count            425 non-null    int64  \n",
      " 17  diversity             425 non-null    int64  \n",
      " 18  diversity_ratio       425 non-null    float64\n",
      " 19  Culture               425 non-null    float64\n",
      " 20  UK                    425 non-null    float64\n",
      " 21  Crimes                425 non-null    float64\n",
      " 22  Situational           425 non-null    float64\n",
      " 23  Immigrants            425 non-null    float64\n",
      " 24  Relationships         425 non-null    float64\n",
      " 25  Politics              425 non-null    float64\n",
      " 26  cluster_LDA           425 non-null    int64  \n",
      " 27  cluster_tfidf         425 non-null    int64  \n",
      " 28  rating_type_encoded   425 non-null    int32  \n",
      "dtypes: float64(11), int32(1), int64(7), object(10)\n",
      "memory usage: 97.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset=['rating'], inplace=True)\n",
    "# Apply LabelEncoder now that missing values in rating_type are handled by dropping rows\n",
    "label_encoder = LabelEncoder()\n",
    "df['rating_type_encoded'] = label_encoder.fit_transform(df['rating_type'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S No.</th>\n",
       "      <th>Tag</th>\n",
       "      <th>URL</th>\n",
       "      <th>Raw Transcript</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>CleanTag</th>\n",
       "      <th>Year</th>\n",
       "      <th>Names</th>\n",
       "      <th>Title</th>\n",
       "      <th>runtime</th>\n",
       "      <th>rating</th>\n",
       "      <th>language</th>\n",
       "      <th>preprocessed_content</th>\n",
       "      <th>rating_type</th>\n",
       "      <th>f_words</th>\n",
       "      <th>s_words</th>\n",
       "      <th>word_count</th>\n",
       "      <th>diversity</th>\n",
       "      <th>diversity_ratio</th>\n",
       "      <th>Culture</th>\n",
       "      <th>UK</th>\n",
       "      <th>Crimes</th>\n",
       "      <th>Situational</th>\n",
       "      <th>Immigrants</th>\n",
       "      <th>Relationships</th>\n",
       "      <th>Politics</th>\n",
       "      <th>cluster_LDA</th>\n",
       "      <th>cluster_tfidf</th>\n",
       "      <th>rating_type_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Michelle Buteau: Welcome to Buteaupia (2020)  ...</td>\n",
       "      <td>https://scrapsfromtheloft.com/comedy/michelle-...</td>\n",
       "      <td>['Michelle Buteauâ€™s Netflix special Welcome to...</td>\n",
       "      <td>michelle buteaus netflix special welcome to bu...</td>\n",
       "      <td>Michelle Buteau: Welcome to Buteaupia (2020)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Michelle Buteau</td>\n",
       "      <td>Welcome to Buteaupia</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>en</td>\n",
       "      <td>michelle buteaus welcome buteaupia showcase ch...</td>\n",
       "      <td>Above Average</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>3222</td>\n",
       "      <td>833</td>\n",
       "      <td>0.258535</td>\n",
       "      <td>0.110807</td>\n",
       "      <td>0.132198</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.727972</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.00097</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S No.                                                Tag  \\\n",
       "0      0  Michelle Buteau: Welcome to Buteaupia (2020)  ...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://scrapsfromtheloft.com/comedy/michelle-...   \n",
       "\n",
       "                                      Raw Transcript  \\\n",
       "0  ['Michelle Buteauâ€™s Netflix special Welcome to...   \n",
       "\n",
       "                                          Transcript  \\\n",
       "0  michelle buteaus netflix special welcome to bu...   \n",
       "\n",
       "                                       CleanTag    Year            Names  \\\n",
       "0  Michelle Buteau: Welcome to Buteaupia (2020)  2020.0  Michelle Buteau   \n",
       "\n",
       "                  Title  runtime  rating language  \\\n",
       "0  Welcome to Buteaupia     58.0     7.0       en   \n",
       "\n",
       "                                preprocessed_content    rating_type  f_words  \\\n",
       "0  michelle buteaus welcome buteaupia showcase ch...  Above Average       22   \n",
       "\n",
       "   s_words  word_count  diversity  diversity_ratio   Culture        UK  \\\n",
       "0       24        3222        833         0.258535  0.110807  0.132198   \n",
       "\n",
       "     Crimes  Situational  Immigrants  Relationships  Politics  cluster_LDA  \\\n",
       "0  0.006003     0.727972    0.020906        0.00097  0.001144            3   \n",
       "\n",
       "   cluster_tfidf  rating_type_encoded  \n",
       "0              4                    0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot features for cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0_LDA  1_LDA  2_LDA  3_LDA  4_LDA  5_LDA  6_LDA  0_tfidf  1_tfidf  2_tfidf  \\\n",
      "0  False  False  False   True  False  False  False    False    False    False   \n",
      "1  False  False  False  False  False   True  False    False    False    False   \n",
      "2  False  False  False  False  False   True  False    False    False    False   \n",
      "3  False  False  False  False  False   True  False    False    False    False   \n",
      "4  False  False  False  False  False  False   True    False    False    False   \n",
      "\n",
      "   3_tfidf  4_tfidf  5_tfidf  6_tfidf  \n",
      "0    False     True    False    False  \n",
      "1    False    False    False     True  \n",
      "2     True    False    False    False  \n",
      "3     True    False    False    False  \n",
      "4     True    False    False    False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create dummy variables for 'cluster_LDA'\n",
    "cluster_LDA_dummies = pd.get_dummies(df['cluster_LDA'])\n",
    "LDA_columns = [str(column) + '_LDA' for column in cluster_LDA_dummies.columns]\n",
    "cluster_LDA_dummies.columns = LDA_columns\n",
    "\n",
    "# Create dummy variables for 'cluster_tfidf'\n",
    "cluster_tfidf_dummies = pd.get_dummies(df['cluster_tfidf'])\n",
    "tfidf_columns = [str(column) + '_tfidf' for column in cluster_tfidf_dummies.columns]\n",
    "cluster_tfidf_dummies.columns = tfidf_columns\n",
    "\n",
    "# Merge the dummy dataframes\n",
    "cluster_df = pd.merge(cluster_LDA_dummies, cluster_tfidf_dummies, right_index=True, left_index=True)\n",
    "\n",
    "# Display the head of the merged dataframe\n",
    "print(cluster_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S No.', 'Tag', 'URL', 'Raw Transcript', 'Transcript', 'CleanTag',\n",
       "       'Year', 'Names', 'Title', 'runtime', 'rating', 'language',\n",
       "       'preprocessed_content', 'rating_type', 'f_words', 's_words',\n",
       "       'word_count', 'diversity', 'diversity_ratio', 'Culture', 'UK', 'Crimes',\n",
       "       'Situational', 'Immigrants', 'Relationships', 'Politics', 'cluster_LDA',\n",
       "       'cluster_tfidf', 'rating_type_encoded', '0_LDA', '1_LDA', '2_LDA',\n",
       "       '3_LDA', '4_LDA', '5_LDA', '6_LDA', '0_tfidf', '1_tfidf', '2_tfidf',\n",
       "       '3_tfidf', '4_tfidf', '5_tfidf', '6_tfidf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, cluster_df, right_index=True, left_index=True)\n",
    "boolean_cols = df.select_dtypes(include='bool').columns\n",
    "for col in boolean_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing sets and train models.\n",
    "\n",
    "- Train Random Forest model\n",
    "\n",
    "- Train SGD model\n",
    "\n",
    "- Perform grid search and train XGB model\n",
    "\n",
    "- Create and ensemble of three classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only LDA Topic assignments to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (Selected Topics): (425, 7)\n",
      "Shape of y: (425,)\n",
      "\n",
      "--- Training Random Forest ---\n",
      "Random Forest Best Params: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Random Forest Test Accuracy: 0.5312\n",
      "Random Forest GridSearchCV Time: 9.64s\n",
      "\n",
      "--- Training SGD Classifier ---\n",
      "SGD Classifier Best Params: {'alpha': 0.001, 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "SGD Classifier Test Accuracy: 0.6250\n",
      "SGD Classifier GridSearchCV Time: 0.11s\n",
      "\n",
      "--- Training XGBoost ---\n",
      "XGBoost Best Params: {'colsample_bytree': 0.5, 'eta': 0.1, 'gamma': 0.2, 'max_depth': 3, 'min_child_weight': 1}\n",
      "XGBoost Test Accuracy: 0.5781\n",
      "XGBoost GridSearchCV Time: 4.05s\n",
      "\n",
      "--- Training Ensemble Voting Classifier ---\n",
      "Ensemble Accuracy: 0.6094\n",
      "\n",
      "--- Classification Report (Ensemble) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66        37\n",
      "           1       0.54      0.56      0.55        27\n",
      "\n",
      "    accuracy                           0.61        64\n",
      "   macro avg       0.60      0.60      0.60        64\n",
      "weighted avg       0.61      0.61      0.61        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# --- Config ---\n",
    "RANDOM_STATE = 1\n",
    "TEST_SIZE = 0.15\n",
    "\n",
    "# --- Data Prep ---\n",
    "X = df.loc[df.rating > 0, ['Culture', 'UK', 'Crimes', 'Situational', 'Immigrants', 'Relationships', 'Politics']].values\n",
    "y = df.loc[df.rating > 0, 'rating_type_encoded'].values\n",
    "\n",
    "print(f'Shape of X (Selected Topics): {X.shape}')\n",
    "print(f'Shape of y: {y.shape}')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# --- Utility: Grid Search Wrapper ---\n",
    "def train_with_grid_search(model, param_grid, model_name):\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    start = time.time()\n",
    "    grid = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    duration = time.time() - start\n",
    "    print(f\"{model_name} Best Params: {grid.best_params_}\")\n",
    "    print(f\"{model_name} Test Accuracy: {grid.best_estimator_.score(X_test_scaled, y_test):.4f}\")\n",
    "    print(f\"{model_name} GridSearchCV Time: {duration:.2f}s\")\n",
    "    return grid.best_estimator_\n",
    "\n",
    "# --- Random Forest ---\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "rf = train_with_grid_search(RandomForestClassifier(random_state=RANDOM_STATE), rf_params, \"Random Forest\")\n",
    "\n",
    "# --- SGD Classifier ---\n",
    "sgd_params = {\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'loss': ['hinge', 'log_loss'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "sgd = train_with_grid_search(SGDClassifier(random_state=RANDOM_STATE), sgd_params, \"SGD Classifier\")\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb_params = {\n",
    "    \"eta\": [0.1, 0.2],\n",
    "    \"max_depth\": [3, 6],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"gamma\": [0.0, 0.2],\n",
    "    \"colsample_bytree\": [0.5, 0.7]\n",
    "}\n",
    "xgb = train_with_grid_search(XGBClassifier(eval_metric='logloss', verbosity=0, random_state=RANDOM_STATE),\n",
    "                             xgb_params, \"XGBoost\")\n",
    "\n",
    "# --- Ensemble Voting ---\n",
    "print(\"\\n--- Training Ensemble Voting Classifier ---\")\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('sgd', sgd), ('xgb', xgb)],\n",
    "    voting='soft', n_jobs=-1\n",
    ")\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "ensemble_acc = ensemble.score(X_test_scaled, y_test)\n",
    "print(f'Ensemble Accuracy: {ensemble_acc:.4f}')\n",
    "\n",
    "# --- Final Evaluation ---\n",
    "print(\"\\n--- Classification Report (Ensemble) ---\")\n",
    "y_pred_ensemble = ensemble.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_ensemble))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Cluster assignments to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (Cluster Assignments): (425, 14)\n",
      "Shape of y: (425,)\n",
      "Unique target values: [0 1]\n",
      "\n",
      "--- Training Random Forest ---\n",
      "Random Forest Best Params: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Test Accuracy: 0.5938\n",
      "Random Forest GridSearchCV Time: 7.99s\n",
      "\n",
      "--- Training SGD Classifier ---\n",
      "SGD Classifier Best Params: {'alpha': 0.001, 'loss': 'modified_huber', 'max_iter': 1000, 'penalty': 'elasticnet'}\n",
      "SGD Classifier Test Accuracy: 0.4844\n",
      "SGD Classifier GridSearchCV Time: 0.09s\n",
      "\n",
      "--- Training XGBoost ---\n",
      "XGBoost Best Params: {'colsample_bytree': 0.5, 'eta': 0.1, 'gamma': 0.2, 'max_depth': 3, 'min_child_weight': 1}\n",
      "XGBoost Test Accuracy: 0.6094\n",
      "XGBoost GridSearchCV Time: 2.26s\n",
      "\n",
      "--- Training Ensemble Voting Classifier ---\n",
      "Ensemble Accuracy: 0.5469\n",
      "\n",
      "--- Classification Report (Ensemble) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.70      0.64        37\n",
      "           1       0.45      0.33      0.38        27\n",
      "\n",
      "    accuracy                           0.55        64\n",
      "   macro avg       0.52      0.52      0.51        64\n",
      "weighted avg       0.53      0.55      0.53        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# --- Config ---\n",
    "RANDOM_STATE = 1\n",
    "\n",
    "# --- Feature Selection ---\n",
    "cluster_cols = ['0_LDA', '1_LDA', '2_LDA', '3_LDA',\n",
    "                '4_LDA', '5_LDA', '6_LDA', '0_tfidf', '1_tfidf', '2_tfidf', '3_tfidf',\n",
    "                '4_tfidf', '5_tfidf', '6_tfidf']\n",
    "\n",
    "X = df[cluster_cols].values\n",
    "y = df['rating_type_encoded'].values\n",
    "\n",
    "print(f\"Shape of X (Cluster Assignments): {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "print(f\"Unique target values: {np.unique(y)}\")\n",
    "\n",
    "# --- Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "# --- Scaling ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Utility: Grid Search Training ---\n",
    "def train_with_grid_search(model, param_grid, model_name):\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    start = time.time()\n",
    "    grid = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    duration = time.time() - start\n",
    "    print(f\"{model_name} Best Params: {grid.best_params_}\")\n",
    "    print(f\"{model_name} Test Accuracy: {grid.best_estimator_.score(X_test_scaled, y_test):.4f}\")\n",
    "    print(f\"{model_name} GridSearchCV Time: {duration:.2f}s\")\n",
    "    return grid.best_estimator_\n",
    "\n",
    "# --- Random Forest ---\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "rf = train_with_grid_search(RandomForestClassifier(random_state=RANDOM_STATE), rf_params, \"Random Forest\")\n",
    "\n",
    "# --- SGD Classifier ---\n",
    "sgd_params = {\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'loss': ['log_loss', 'modified_huber'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "sgd = train_with_grid_search(SGDClassifier(random_state=RANDOM_STATE), sgd_params, \"SGD Classifier\")\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb_params = {\n",
    "    \"eta\": [0.1, 0.2],\n",
    "    \"max_depth\": [3, 6],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"gamma\": [0.0, 0.2],\n",
    "    \"colsample_bytree\": [0.5, 0.7]\n",
    "}\n",
    "xgb = train_with_grid_search(XGBClassifier(eval_metric='logloss', verbosity=0, random_state=RANDOM_STATE),\n",
    "                             xgb_params, \"XGBoost\")\n",
    "\n",
    "# --- Ensemble ---\n",
    "print(\"\\n--- Training Ensemble Voting Classifier ---\")\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('sgd', sgd), ('xgb', xgb)],\n",
    "    voting='soft', n_jobs=-1\n",
    ")\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "ensemble_acc = ensemble.score(X_test_scaled, y_test)\n",
    "print(f\"Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "print(\"\\n--- Classification Report (Ensemble) ---\")\n",
    "y_pred_ensemble = ensemble.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_ensemble))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both cluster assignments and LDA probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (Combined Features): (425, 21)\n",
      "Shape of y: (425,)\n",
      "Unique target values: [0 1]\n",
      "\n",
      "--- Training Random Forest ---\n",
      "Random Forest Best Params: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Random Forest Accuracy: 0.5781\n",
      "Random Forest GridSearch Time: 10.52s\n",
      "\n",
      "--- Training SGD Classifier ---\n",
      "SGD Classifier Best Params: {'alpha': 0.0001, 'loss': 'modified_huber', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "SGD Classifier Accuracy: 0.5938\n",
      "SGD Classifier GridSearch Time: 0.09s\n",
      "\n",
      "--- Training XGBoost ---\n",
      "XGBoost Best Params: {'colsample_bytree': 0.7, 'eta': 0.2, 'gamma': 0.2, 'max_depth': 3, 'min_child_weight': 1}\n",
      "XGBoost Accuracy: 0.5469\n",
      "XGBoost GridSearch Time: 2.99s\n",
      "\n",
      "--- Training Ensemble Voting Classifier ---\n",
      "Ensemble Accuracy: 0.5938\n",
      "\n",
      "--- Classification Report (Ensemble) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.43      0.55        37\n",
      "           1       0.51      0.81      0.63        27\n",
      "\n",
      "    accuracy                           0.59        64\n",
      "   macro avg       0.64      0.62      0.59        64\n",
      "weighted avg       0.66      0.59      0.58        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# --- Config ---\n",
    "RANDOM_STATE = 1\n",
    "\n",
    "# --- Feature Set ---\n",
    "X_columns = ['Culture', 'UK', 'Crimes', 'Situational', 'Immigrants',\n",
    "             'Relationships', 'Politics', '0_LDA', '1_LDA', '2_LDA', '3_LDA',\n",
    "             '4_LDA', '5_LDA', '6_LDA', '0_tfidf', '1_tfidf', '2_tfidf', '3_tfidf',\n",
    "             '4_tfidf', '5_tfidf', '6_tfidf']\n",
    "\n",
    "X = df[X_columns].values\n",
    "y = df['rating_type_encoded'].values\n",
    "\n",
    "print(f\"Shape of X (Combined Features): {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "print(f\"Unique target values: {np.unique(y)}\")\n",
    "\n",
    "# --- Split and Scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, stratify=y, random_state=RANDOM_STATE)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Grid Search Utility ---\n",
    "def train_with_grid_search(model, param_grid, name):\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    start = time.time()\n",
    "    grid = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    duration = time.time() - start\n",
    "    print(f\"{name} Best Params: {grid.best_params_}\")\n",
    "    print(f\"{name} Accuracy: {grid.best_estimator_.score(X_test_scaled, y_test):.4f}\")\n",
    "    print(f\"{name} GridSearch Time: {duration:.2f}s\")\n",
    "    return grid.best_estimator_\n",
    "\n",
    "# --- Random Forest Grid Search ---\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "rf = train_with_grid_search(RandomForestClassifier(random_state=RANDOM_STATE), rf_params, \"Random Forest\")\n",
    "\n",
    "# --- SGD Grid Search (ensure losses support predict_proba) ---\n",
    "sgd_params = {\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'loss': ['log_loss', 'modified_huber'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "sgd = train_with_grid_search(SGDClassifier(random_state=RANDOM_STATE), sgd_params, \"SGD Classifier\")\n",
    "\n",
    "# --- XGBoost Grid Search ---\n",
    "xgb_params = {\n",
    "    \"eta\": [0.1, 0.2],\n",
    "    \"max_depth\": [3, 6],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"gamma\": [0.0, 0.2],\n",
    "    \"colsample_bytree\": [0.5, 0.7]\n",
    "}\n",
    "xgb = train_with_grid_search(\n",
    "    XGBClassifier(eval_metric='logloss', use_label_encoder=False, verbosity=0, random_state=RANDOM_STATE),\n",
    "    xgb_params,\n",
    "    \"XGBoost\"\n",
    ")\n",
    "\n",
    "# --- Voting Ensemble ---\n",
    "print(\"\\n--- Training Ensemble Voting Classifier ---\")\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('sgd', sgd), ('xgb', xgb)],\n",
    "    voting='soft', n_jobs=-1\n",
    ")\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "ensemble_acc = ensemble.score(X_test_scaled, y_test)\n",
    "print(f\"Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
    "\n",
    "# --- Final Evaluation ---\n",
    "print(\"\\n--- Classification Report (Ensemble) ---\")\n",
    "y_pred = ensemble.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "The primary objective was to build and evaluate machine learning models to predict the `rating_type` (binary classification: 'Above Average' vs 'Below Average') of stand-up comedy specials.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset and Features\n",
    "After preprocessing and dropping missing `rating` values, the dataset contained **425 samples**. The target variable `rating_type` was encoded as:\n",
    "- `0` â†’ Below Average\n",
    "- `1` â†’ Above Average\n",
    "\n",
    "Three distinct feature sets were evaluated:\n",
    "\n",
    "1. **Selected Topics** (7 features):  \n",
    "   Continuous scores from predefined topics such as `'Culture'`, `'UK'`, `'Crimes'`, `'Situational'`, `'Immigrants'`, `'Relationships'`, and `'Politics'`.\n",
    "\n",
    "2. **Cluster Assignments** (14 features):  \n",
    "   One-hot encoded binary flags for unsupervised clustering via **LDA** and **TF-IDF** (`0_LDA` to `6_LDA` and `0_tfidf` to `6_tfidf`).\n",
    "\n",
    "3. **Combined Features** (21 features):  \n",
    "   A union of the above two, leveraging both semantic topic scores and latent cluster patterns.\n",
    "\n",
    "All features were scaled using `StandardScaler`.\n",
    "\n",
    "---\n",
    "\n",
    "## Models Evaluated\n",
    "For each feature set, the following models were trained using **GridSearchCV (except ensemble)** and evaluated on a **15% hold-out test set**:\n",
    "\n",
    "- **Random Forest Classifier**\n",
    "- **SGD Classifier** (only `log_loss` or `modified_huber` used to enable `predict_proba`)\n",
    "- **XGBoost Classifier**\n",
    "- **Voting Ensemble Classifier** (`soft` voting using RF, SGD, and XGB)\n",
    "\n",
    "---\n",
    "\n",
    "## Performance Summary â€“ Ensemble Classifier\n",
    "\n",
    "| Feature Set             | Accuracy | Class 0 (P/R/F1)      | Class 1 (P/R/F1)      |\n",
    "|-------------------------|----------|------------------------|------------------------|\n",
    "| **Selected Topics**     | **0.6094** | 0.67 / 0.65 / 0.66     | 0.54 / 0.56 / 0.55     |\n",
    "| **Cluster Assignments** | 0.5469   | 0.59 / 0.70 / 0.64     | 0.45 / 0.33 / 0.38     |\n",
    "| **Combined Features**   | **0.5938** | **0.76 / 0.43 / 0.55** | **0.51 / 0.81 / 0.63** |\n",
    "\n",
    "- *Test Set Size: 64 (Class 0: 37, Class 1: 27)*\n",
    "\n",
    "---\n",
    "\n",
    "## Analysis\n",
    "\n",
    "### Why the Combined Features Ensemble Is Preferred\n",
    "\n",
    "1. **Best Balance for Class 1 (Above Average)**  \n",
    "   - **Recall = 0.81** â†’ Captures the most true positives for Class 1.\n",
    "   - **F1-score = 0.63** â†’ Best trade-off between precision and recall for Class 1.\n",
    "\n",
    "2. **Highest Class 0 Precision (0.76)**  \n",
    "   Indicates strong confidence when predicting a special as Below Average â€” fewer false positives.\n",
    "\n",
    "3. **Competitive Accuracy (0.5938)**  \n",
    "   Slightly behind the top-performing \"Selected Topics\" ensemble (0.6094) but offers **superior balance across both classes**, especially Class 1 which is often more business-critical.\n",
    "\n",
    "4. **Richest Feature Space**  \n",
    "   By combining handcrafted and learned features, the model generalizes better to diverse patterns in the data.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Decision\n",
    "**The Voting Ensemble trained on \"Combined Features\" (21 total features)** is selected as the best model due to its:\n",
    "\n",
    "- Superior Class 1 detection (recall and F1)\n",
    "- Strong precision for Class 0\n",
    "- Balanced performance across metrics\n",
    "- Generalized feature set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (425, 21), y shape: (425,)\n",
      "Model and scaler saved.\n",
      "Predicted class: 1\n",
      "Prediction probabilities: [0.33708372 0.66291628]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# === STEP 1: Preprocessed DataFrame 'df' must already exist ===\n",
    "df=pd.read_csv(r\"D:\\PROJECTS\\transnlp\\data\\processed\\processed_content_with_clusters.csv\")\n",
    "df.dropna(subset=['rating'], inplace=True)\n",
    "# Apply LabelEncoder now that missing values in rating_type are handled by dropping rows\n",
    "label_encoder = LabelEncoder()\n",
    "df['rating_type_encoded'] = label_encoder.fit_transform(df['rating_type'])\n",
    "# - All _LDA and _tfidf columns are int\n",
    "df = pd.merge(df, cluster_df, right_index=True, left_index=True)\n",
    "boolean_cols = df.select_dtypes(include='bool').columns\n",
    "for col in boolean_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "    \n",
    "# === STEP 2: Final Feature Set ===\n",
    "X_columns = [\n",
    "    'Culture', 'UK', 'Crimes', 'Situational', 'Immigrants', 'Relationships', 'Politics',\n",
    "    '0_LDA', '1_LDA', '2_LDA', '3_LDA', '4_LDA', '5_LDA', '6_LDA',\n",
    "    '0_tfidf', '1_tfidf', '2_tfidf', '3_tfidf', '4_tfidf', '5_tfidf', '6_tfidf'\n",
    "]\n",
    "\n",
    "X_full = df[X_columns].values\n",
    "y_full = df['rating_type_encoded'].values\n",
    "\n",
    "print(f\"X shape: {X_full.shape}, y shape: {y_full.shape}\")\n",
    "\n",
    "# === STEP 3: Scale Features ===\n",
    "scaler = StandardScaler()\n",
    "X_full_scaled = scaler.fit_transform(X_full)\n",
    "\n",
    "# === STEP 4: Train Final Models ===\n",
    "# Best XGBoost Params from GridSearchCV\n",
    "xgb_best_params = {\n",
    "    'colsample_bytree': 0.3,\n",
    "    'eta': 0.05,\n",
    "    'gamma': 0.4,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1\n",
    "}\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=101, random_state=1)\n",
    "model_rf.fit(X_full_scaled, y_full)\n",
    "\n",
    "model_sgd = SGDClassifier(loss='modified_huber', random_state=1)\n",
    "model_sgd.fit(X_full_scaled, y_full)\n",
    "\n",
    "model_xgb = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=1,\n",
    "    **xgb_best_params\n",
    ")\n",
    "model_xgb.fit(X_full_scaled, y_full)\n",
    "\n",
    "# === STEP 5: Build and Train Ensemble ===\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', model_rf), ('sgd', model_sgd), ('xgb', model_xgb)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "ensemble.fit(X_full_scaled, y_full)\n",
    "\n",
    "# === STEP 6: Save Models ===\n",
    "joblib.dump(ensemble, 'production_ensemble_model.joblib')\n",
    "joblib.dump(scaler, 'production_scaler.joblib')\n",
    "print(\"Model and scaler saved.\")\n",
    "\n",
    "# === STEP 7: Predict on New Data Example ===\n",
    "new_data = pd.DataFrame([\n",
    "    [0.1, 0.2, 0.05, 0.8, 0.15, 0.3, 0.01, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "], columns=X_columns)\n",
    "\n",
    "new_scaled = scaler.transform(new_data)\n",
    "encoded_pred = ensemble.predict(new_scaled)\n",
    "proba_pred = ensemble.predict_proba(new_scaled)\n",
    "\n",
    "print(f\"Predicted class: {encoded_pred[0]}\")\n",
    "print(f\"Prediction probabilities: {proba_pred[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
