{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chains can be used for very basic text generation. Takes every word in a corpus as a state. A simple assumption is made that the next word is only dependent on the previous word ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SUNSHINE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    '''Tokenize the input text by sentence and word.'''\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple Markov chain function that creates a dictionary:\n",
    "* The keys should be all of the words in the corpus\n",
    "* The values should be a list of the words that follow the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_markov_chain(tokenized_text):\n",
    "    '''Build a Markov chain dictionary from the tokenized text.\n",
    "       The input is a string of text and the output will be a dictionary with each word as\n",
    "       a key and each value as the list of words that come after the key in the text.'''\n",
    "    \n",
    "    m_dict = defaultdict(list)\n",
    "    for sentence in tokenized_text:\n",
    "        m_dict['START'].append(sentence[0])  # Add 'START' token\n",
    "        for current_word, next_word in zip(sentence, sentence[1:]):\n",
    "            m_dict[current_word].append(next_word)\n",
    "    return dict(m_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(chain, start_word='START', count=15, randomness=1.0):\n",
    "    '''Generate a sentence using the Markov chain dictionary.'''\n",
    "    sentence = []\n",
    "    current_word = start_word\n",
    "\n",
    "    for _ in range(count):\n",
    "        next_word_options = chain[current_word]\n",
    "        if not next_word_options:\n",
    "            break\n",
    "        next_word = random.choice(next_word_options)\n",
    "        sentence.append(next_word)\n",
    "        current_word = next_word\n",
    "\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"frame2.csv\")\n",
    "com_text = data.Transcript.loc[0] # Extract text of any comedian using serial number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenized_text = tokenize_text(com_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Markov chain dictionary\n",
    "com_dict = build_markov_chain(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey hey did have you know what struck me up and night he goes i told me i have to me two times because well sometimes theyre like that happened i tom he goes yeah it six months ago i do you get fuckin piece on a sixyearold let me a magazine or meeting tom the same it is nice\n"
     ]
    }
   ],
   "source": [
    "# Generate a sentence\n",
    "generated_sentence = generate_sentence(com_dict, start_word='START', count=60)\n",
    "print(generated_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The generated text looks like English with  a few spelling errors though it doesn't really make much sense. There are grammar and syntax errors everywhere but this is partially to be expected given that the source text is composed of transcripts from spoken stand-up comedy routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
